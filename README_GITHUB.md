# ğŸ” Multimodal RAG System - SIH 2025

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![GPU Accelerated](https://img.shields.io/badge/GPU-Accelerated-green.svg)](https://developer.nvidia.com/cuda-zone)

**A production-ready Multimodal Retrieval-Augmented Generation (RAG) system for NTRO's Smart India Hackathon 2025**

> ğŸ† **Built for:** National Technical Research Organisation (NTRO)  
> ğŸ¯ **Category:** Software | Smart Automation  
> ğŸ’¡ **Theme:** Offline Multimodal Intelligence with LLM Grounding

## ğŸ“‹ Problem Statement

Design and build a multimodal RAG system that can **ingest, index, and query diverse data formats** (DOC, PDF, Images, Audio) within a **unified semantic retrieval framework** using a **Large Language Model in OFFLINE mode**.

## âœ¨ Key Features

### ğŸ¯ Core Capabilities
- âœ… **Multimodal Ingestion**: PDF, DOCX, TXT, Images (PNG/JPG), Audio (MP3/WAV/M4A/FLAC)
- âœ… **OCR Integration**: EasyOCR with GPU acceleration for text extraction from images
- âœ… **Speech-to-Text**: Faster-Whisper for high-speed audio transcription
- âœ… **Vector Database**: ChromaDB for semantic search across all modalities
- âœ… **Offline LLM**: Phi-3 via Ollama (no internet required)
- âœ… **GPU Optimized**: Full CUDA acceleration (20-30% faster responses)
- âœ… **ChatGPT-Style UI**: Clean, professional web interface

### ğŸ” Search Modes
1. **Text Query** - Natural language questions
2. **Image Query** - Upload images/screenshots, extract text via OCR, find related content
3. **Audio Query** - Upload voice recordings, transcribe, search semantically

### ğŸ“Š Advanced Features
- **Quality Scoring**: Relevance percentages for each source (0-100%)
- **Citation Tracking**: Numbered references with source file links
- **Cross-Format Search**: Text embeddings + CLIP visual embeddings
- **Source Navigation**: View original files, timestamps, and metadata
- **Statistics Dashboard**: Real-time metrics on indexed content

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10 or higher
- NVIDIA GPU with CUDA support (recommended for speed)
- 8GB RAM minimum (16GB recommended)
- 10GB free disk space

### Installation

1. **Clone the repository:**
```bash
git clone https://github.com/YOUR_USERNAME/multimodal_rag_free.git
cd multimodal_rag_free
```

2. **Create virtual environment:**
```bash
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # Linux/Mac
```

3. **Install dependencies:**
```bash
pip install -r requirements.txt
```

4. **Install Ollama and Phi-3 model:**
```bash
# Download Ollama from https://ollama.ai
ollama pull phi3
```

5. **Start the server:**
```bash
# Option 1: Double-click START_HERE.bat (Windows)

# Option 2: Command line
python run_server.py

# Option 3: GPU-optimized startup
START_SERVER_GPU_OPTIMIZED.bat
```

6. **Open browser:**
Navigate to `http://127.0.0.1:8000`

## ğŸ“– Usage Guide

### 1ï¸âƒ£ Upload Documents
- Click "Choose Files" and select your documents, images, or audio files
- Multiple file types supported in one upload
- System automatically processes and indexes content

### 2ï¸âƒ£ Query Your Data

**Text Mode:**
```
Example: "How to make one pan chicken?"
```

**Image Mode:**
- Upload an image or screenshot
- System extracts text via OCR
- Searches for related documents and images

**Audio Mode:**
- Upload voice recording or audio file
- System transcribes speech
- Searches for matching content

### 3ï¸âƒ£ View Results
- **Answer**: Structured response with Summary, Key Points, Steps, Insights, Takeaway
- **Sources**: Numbered citations with relevance scores
- **View Source**: Click to open original files

## ğŸ—ï¸ Project Structure

```
multimodal_rag_free/
â”œâ”€â”€ app.py                 # FastAPI server with endpoints
â”œâ”€â”€ run_server.py          # Server launcher
â”œâ”€â”€ generator.py           # Multi-backend LLM generator
â”œâ”€â”€ llama_query.py         # Answer generation orchestrator
â”œâ”€â”€ embeddings.py          # Text embedding engine (sentence-transformers)
â”œâ”€â”€ clip_embeddings.py     # Image embedding engine (CLIP)
â”œâ”€â”€ ocr_engine.py          # OCR processing (EasyOCR)
â”œâ”€â”€ ingestion.py           # Document processing pipeline
â”œâ”€â”€ indexer.py             # ChromaDB vector store manager
â”œâ”€â”€ utils.py               # Prompt engineering templates
â”œâ”€â”€ format_answer.py       # Answer post-processing
â”œâ”€â”€ web/                   # Frontend interface
â”‚   â””â”€â”€ index.html         # Modern single-page UI
â”œâ”€â”€ chroma_db/             # Vector database (gitignored)
â”œâ”€â”€ uploads/               # Uploaded files (gitignored)
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ .env                   # Configuration file
â””â”€â”€ START_HERE.bat         # Quick launcher
```

## âš™ï¸ Configuration

Edit `.env` to customize:

```properties
# Database
CHROMA_PERSIST_DIR=./chroma_db

# LLM Model
LLAMA_MODEL_PATH=phi3
LLAMA_MODEL_ID=phi3

# Device
EMBED_DEVICE=cuda  # or 'cpu'

# Audio
WHISPER_MODEL=base

# Server
PORT=8000
```

## ğŸ¯ SIH 2025 Requirements Compliance

| Requirement | Implementation | Status |
|------------|----------------|--------|
| Multimodal Ingestion | PDF, DOCX, TXT, Images, Audio | âœ… |
| OCR for Images | EasyOCR with GPU | âœ… |
| Speech-to-Text | Faster-Whisper | âœ… |
| Vector Indexing | ChromaDB + CLIP | âœ… |
| Semantic Search | Unified vector space | âœ… |
| LLM Generation | Phi-3 (Offline) | âœ… |
| Natural Language Query | Plain text interface | âœ… |
| Citation Transparency | Numbered references | âœ… |
| Source Navigation | File viewing | âœ… |
| GPU Acceleration | CUDA optimized | âœ… |

## ğŸ”§ GPU Optimization

For maximum performance with NVIDIA GPUs:

```bash
# Option 1: Use optimized startup script
START_SERVER_GPU_OPTIMIZED.bat

# Option 2: Set environment variables manually
$env:OLLAMA_NUM_GPU=999
$env:OLLAMA_MAX_LOADED_MODELS=1
$env:OLLAMA_FLASH_ATTENTION=1
python run_server.py
```

**Expected Improvements:**
- 20-30% faster LLM generation
- Lower latency between queries
- Model stays in GPU memory (no reload delay)

## ğŸ“Š Performance Metrics

- **Response Time**: 5-7 seconds per query (GPU optimized)
- **Accuracy**: 85-95% relevance with quality scoring
- **Throughput**: Handles 100+ documents, images, audio files
- **Memory**: ~4GB GPU VRAM, ~8GB system RAM

## ğŸ› ï¸ Troubleshooting

### Server Won't Start
```bash
# Check if port is available
netstat -ano | findstr :8000

# Verify Ollama is running
ollama list
```

### Slow Performance
```bash
# Use GPU-optimized startup
START_SERVER_GPU_OPTIMIZED.bat

# Check CUDA availability
python -c "import torch; print(torch.cuda.is_available())"
```

### OCR Not Working
- EasyOCR downloads models on first use (~500MB)
- Ensure stable internet for initial setup
- Check GPU drivers are installed

## ğŸ¤ Contributing

This project is part of SIH 2025. For contributions:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¥ Team

**Organization:** National Technical Research Organisation (NTRO)  
**Theme:** Smart Automation  
**Year:** 2025

## ğŸ™ Acknowledgments

- **Ollama** - Offline LLM deployment
- **ChromaDB** - Vector database
- **OpenAI CLIP** - Visual embeddings
- **EasyOCR** - Text extraction
- **Faster-Whisper** - Audio transcription

## ğŸ“§ Contact

For questions or support, please open an issue in the GitHub repository.

---

**Built with â¤ï¸ for Smart India Hackathon 2025**
